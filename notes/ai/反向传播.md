# 大模型学习原理

## 神经网络基础

模型中，不论是词嵌入、注意力机制还是前馈神经网络，都可以看做由众多神经元组成的网络，其基础都是矩阵、向量运算。

每个神经元的计算逻辑为：

$y = [\begin{array}{}x_1&x_2&...&x_n\end{array}] * [\begin{array}{}w_1\\w_2\\.\\.\\.\\w_n\end{array}] + b$

其中，偏置值b可以表示神经元激活的难易程度。

多个神经元在一起形成一层神经网络，每一层网络中神经元的输入来自于上层网络的每一个神经元。

$\vec{Y} = \vec{X} * \left( \begin{array}{}\vec{w_1} & ... & \vec{w_n}\end{array}\right) + \vec{B}$

这篇文档主要解释一下在训练过程中，样本输入、处理，如何调整参数值。

首先，样本被神经网络处理后会得到处理结果，可记作$y^{real}$，而实际期望的结果记为$y^{expect}$。

其次，需要选择一种方式来量化实际结果与期望结果的差异，损失函数可以记作 $cost = (y^{real} - y^{expect})^2 = \sum(y^{real}_{i} - y^{expect}_{i})^2$

对于上述损失函数，我们的目标是尽量是函数值最小化，即 $\frac{d{cost}}{d{y^{real}}} = 0$

## 梯度下降

梯度是多元函数在向量场中变化最快的方向，可类比于函数的导数，对于函数$f(x, y)$，其梯度 $\nabla{f(x,y)} = (\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y})$，即f对于x、y的偏导数。

对于函数f上的点，沿着梯度方向变化可是函数值快速下降。
也就是说，对于上述神经网络损失函数来说，我们可以通过梯度下降的方法，逐步沿着梯度下降方向调整$y^{real}$中的这一层神经网络中的w、x、b中的参数值，实现最小化损失函数cost的值。
实际上，梯度向量指明了在向量场中移动的方向，即沿着梯度下降的方向调整参数时，函数值变化最快。通过一步步按照梯度下降调整参数，可以使函数值最终陷入场中一个局部最小的“坑”中。

同时，梯度向量中各个数值的相对大小，指明了调整参数的影响力，**数值越大，说明参数对方向的影响力越大。**

## 反向传播

梯度下降解决了一层神经网络中多个神经元，如何根据样本反馈进行调整参数，使得输入值趋近期望的方法。
但是模型中神经网络多层叠加，每层神经网络在训练中均需要调整参数值，使得整体的损失函数值最小。

第N层神经元输出向量通过梯度下降趋近于期望值，在这个过程中，有三个路径可以实现：
- 改变输入矩阵值；
- 改变权重矩阵值；
- 改变偏置向量值；

由于第N层神经网络的输入值就是第N-1层神经网络的输出，改变输入矩阵值就是改变上层神经网络的输出值。

第N层神经元与第N-1层神经元之间为全连接，即第N层第某个神经元输入值需要降低时，第N-1层每个神经元的输出都需要降低。
假设没层神经网络均有M个神经元。
从第N-1层网络看，层内每一个神经元收到从第N层收到M个神经元的调节信号，这些信号按照梯度向量中的数值具有不同的影响力。
第N-1层的神经元综合M个调节信号，决定如何调节自己的输出值，这就是反向传播的逻辑，这个逻辑会一直传递、调整到第1层神经网络。

反向传播解决了多层神经网络结构怎样训练的问题，数学依据为链式求导。
在链式求导中，有很多值是可以存下来避免重复计算的。

举个例子，假设有:
$$ L_1 = a_1 * x + b_1 $$
$$ L_2 = a_2 * L_1 + b_2 $$
$$\frac{\partial{L_2}}{\partial{a_1}} = \frac{\partial{L_2}}{\partial{L_1}} * \frac{\partial{L_1}}{\partial{a_1}}$$
$$\frac{\partial{L_2}}{\partial{b_1}} = \frac{\partial{L_2}}{\partial{L_1}} * \frac{\partial{L_1}}{\partial{b_1}}$$
$\frac{\partial{L_2}}{\partial{L_1}}$会在计算中反复用到。



## 模型训练

模型训练过程中，每个样本都会进行反向传播，对每层神经网络中的权重、输入、偏置值都会有不同调整。
batch对于每层神经网络权重、输入、偏置的调整，需要考虑Batch中所有样本，通常对所有变化量取均值进行确定最终变化量。

最终变化量结合学习率计算最终调整量。














 